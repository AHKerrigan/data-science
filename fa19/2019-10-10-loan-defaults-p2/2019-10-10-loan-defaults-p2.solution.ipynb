{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"### BEGIN SOLUTION","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\ntrain = pd.read_csv(\"../input/ucfai-dsg-fa19-default/train.csv\")\ntest = pd.read_csv(\"../input/ucfai-dsg-fa19-default/test.csv\")\nID_test = test['id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['GOOD_STANDING'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# So there are 9x as many good loans as bad (naturally, any reputable lender would avoid bad loans)\n# This is problomatic, because most models will notice that most features are associated with good loans\n# Therefore, they will most likely just predict all good loans. Why is this a problem?\n\n# The score for this comp is an AUC ROC metric. In an oversimplified sense, this score is based on both\n# how precise your positives are AND your negatives\n# If you guess on either of them, you should expect the lowest score (0.5)\n\n# There are almost 1 million examples, it is safe to undersample\n# Undersampling is basically where we only use a subset of the training data so that our good loans/bad loans are equal\n# The simple solution to this is just to randomly choose good loans to use until we are equal to bad loans\n# Here is how we are going to undersample\nimport numpy as np\n\n# Give me the -length - of the subset of -train- made up of entries with GOOD_STANDING == 0 \n# In otherwords, how many bad loans are there?\nbad_standing_len = len(train[train[\"GOOD_STANDING\"] == 0])\n\n# Give me the index of the subset of train where good_standing == 1 \n# In otherwords, give me the index of all the good loans\ngood_standing_index = train[train['GOOD_STANDING'] == 1].index\n\n# Randomly choose indices of good loans equal to the number of bad loans\nrandom_index = np.random.choice(good_standing_index, bad_standing_len, replace=False)\n\n# Give me the index of all the bad loans in train\nbad_standing_index = train[train['GOOD_STANDING'] == 0].index\n\n# Concatonate the indices of bad loans, and our randomly sampled good loans\nunder_sample_index = np.concatenate([bad_standing_index, random_index])\n\n# Create a new pandas dataframe made only of these indices \nunder_sample = train.loc[under_sample_index]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make sure it works, and make this undersampled dataframe our train\ntrain['GOOD_STANDING'].value_counts()\nunder_sample['GOOD_STANDING'].value_counts()\ntrain = under_sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As we did in Titanic, lets concatonate train and test\ntrain.head()\ntrain_len = len(train)\ndataset =  pd.concat(objs=[train, test], axis=0).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = dataset.fillna(np.nan)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(dataset.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# There are a lot of columns and a lot of nulls, so I'm going to just delete features that have more than 20% of the data missing and go from there\n\nnull_list = dataset.isnull().sum()\nfor column, missing_num in null_list.iteritems():\n    if column != \"GOOD_STANDING\":\n        if missing_num / len(dataset.index) > 0.2:\n            dataset = dataset.drop([column], axis = 1)\ndataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since \"sub grade\" exists, grade is kind of redundant, let's just get rid of grade\ndataset.drop(['grade'], axis=1, inplace=True)\n\n# We're also going to remove issue date because, as we discussed last week, the issue date\n# between the train and the test is unbalanced. Therefore, there is likely not much to learn from it\ndataset.drop(['issue_d'], axis=1, inplace=True)\n\n\n# I'm also going to remove employee title. This might seem problamatic, but consider two things\n# We already have annual income, really how much more info can we gloss from this?\n# If we have to turn these into dummy variables, as we tend to do, there are a LOT of different titles, they will be sparse\ndataset.drop(['emp_title'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Under most circumstances, you want to go through and replace nulls intelligently, but to give you an idea on how to efficiently clean\n# this dataset, let's try replacing all continious values with the mean, and all categorical values with the mode\n\nnumber_set = set(dataset._get_numeric_data().columns)\nfor i,j in dataset.iteritems():\n    print(\"Now handeling\", i)\n    # Let's break this down (it was also used in titanic)\n    # For each column in the dataset, take the subset of that column made up of null entries for that column\n    # Then, take that subset's indices and transform it into a list\n    NaN_index = list(dataset[i][dataset[i].isnull()].index)\n    # Skip the target variable obviously\n    if (i == 'GOOD_STANDING'):\n        continue\n    if i in number_set:\n        # If we are dealing with numerial values, take the median\n        med = dataset[i].mean()\n        for x in NaN_index:\n            #print(\"did I get here\")\n            dataset[i].iloc[x] = med\n    else:\n        # Otherwise, just take the most frequent categorical value \n        mode = dataset[i].value_counts().idxmax()\n        for x in NaN_index:\n           # print(\"what about here\")\n            dataset[i].iloc[x] = mode\n            \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We're going to drop a couple categorical values that have way to many possible values\n# There are certainly ways you can utilize this, expecially the dates, but for the time being we will remove them\n# If there are too many possible values, get_dummies creates too many new columns\ndataset = dataset.drop(['earliest_cr_line', 'last_credit_pull_d', 'last_pymnt_d', 'addr_state', 'title'], axis=1)\n\ncategorical_features = list(set(dataset.columns) - set(dataset._get_numeric_data().columns))\n\nprint(categorical_features)\ndataset = pd.get_dummies(dataset, columns=categorical_features)\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()\ndataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separate train and test\ntrain = dataset[:train_len]\ntest = dataset[train_len:]\n# Drop the good standing from test (which should all be empty)\ntest.drop(labels=[\"GOOD_STANDING\"],axis = 1,inplace=True)\n\n# Make sure they are ints\ntrain[\"GOOD_STANDING\"] = train[\"GOOD_STANDING\"].astype(int)\n\nY_train = train[\"GOOD_STANDING\"]\n\nX_train = train.drop(labels = [\"GOOD_STANDING\"],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's jus tuse a basic random forest\nRF = RandomForestClassifier()\nRF.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_standing = pd.Series(RF.predict(test), name=\"GOOD_STANDING\")\n\nresults = pd.concat([ID_test,test_standing],axis=1)\n\nresults.to_csv(\"GradePrediction.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### END SOLUTION","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}